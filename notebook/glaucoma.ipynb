{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Deolinda1506/ml/blob/main/notebook/glaucoma.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Glaucoma Detection - Model Training and Evaluation \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RScY2K1xnXbD"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'Python 3.13.5' requires the ipykernel package.\n",
            "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
            "\u001b[1;31mOr install 'ipykernel' using the command: '/usr/local/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "sys.path.append('../src')\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import warnings\n",
        "import json\n",
        "from datetime import datetime\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Import our custom modules\n",
        "from preprocessing import ImagePreprocessor\n",
        "from model import GlaucomaDetectionModel\n",
        "from prediction import PredictionService\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "print(\"GPU available:\", tf.config.list_physical_devices('GPU'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"1. DATA LOADING AND PREPROCESSING\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Initialize preprocessor\n",
        "preprocessor = ImagePreprocessor(img_size=(224, 224))\n",
        "\n",
        "# Load dataset\n",
        "print(\"Loading dataset...\")\n",
        "train_images, train_labels = preprocessor.load_dataset('../data/train')\n",
        "test_images, test_labels = preprocessor.load_dataset('../data/test')\n",
        "\n",
        "print(f\"Training set: {train_images.shape[0]} images\")\n",
        "print(f\"Test set: {test_images.shape[0]} images\")\n",
        "print(f\"Image shape: {train_images.shape[1:]}\")\n",
        "print(f\"Classes: {np.unique(train_labels)}\")\n",
        "\n",
        "# Analyze dataset characteristics\n",
        "print(\"\\nDataset Analysis:\")\n",
        "analysis = preprocessor.analyze_dataset('../data/train')\n",
        "print(json.dumps(analysis, indent=2))\n",
        "\n",
        "# Create visualizations\n",
        "print(\"\\nCreating dataset visualizations...\")\n",
        "os.makedirs('../static', exist_ok=True)\n",
        "preprocessor.create_visualizations('../data/train', save_path='../static/dataset_analysis.png')\n",
        "\n",
        "# Split training data into train and validation\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    train_images, train_labels, \n",
        "    test_size=0.2, \n",
        "    random_state=42, \n",
        "    stratify=train_labels\n",
        ")\n",
        "\n",
        "print(f\"\\nData splits:\")\n",
        "print(f\"Training set: {X_train.shape[0]} images\")\n",
        "print(f\"Validation set: {X_val.shape[0]} images\")\n",
        "print(f\"Test set: {test_images.shape[0]} images\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"2. MODEL ARCHITECTURE AND TRAINING\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Create and compile model\n",
        "model = GlaucomaDetectionModel(\n",
        "    input_shape=(224, 224, 3),\n",
        "    model_type='custom'\n",
        ")\n",
        "\n",
        "# Create model\n",
        "model.create_model()\n",
        "model.compile_model(learning_rate=0.001, optimizer_name='adam')\n",
        "\n",
        "# Display model summary\n",
        "print(\"Model Architecture:\")\n",
        "print(model.get_model_summary())\n",
        "\n",
        "# Create data generators with augmentation\n",
        "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    zoom_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "val_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Create generators\n",
        "batch_size = 32\n",
        "train_generator = train_datagen.flow(\n",
        "    X_train, y_train,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_generator = val_datagen.flow(\n",
        "    X_val, y_val,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "print(\"\\nStarting model training...\")\n",
        "os.makedirs('../models', exist_ok=True)\n",
        "history = model.train(\n",
        "    train_generator, \n",
        "    val_generator,\n",
        "    epochs=30,  # Reduced for faster training\n",
        "    batch_size=batch_size,\n",
        "    model_save_path='../models/glaucoma_model.h5'\n",
        ")\n",
        "\n",
        "print(\"Training completed!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"3. MODEL EVALUATION\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Plot training history\n",
        "print(\"Creating training history visualization...\")\n",
        "model.plot_training_history(save_path='../static/training_history.png')\n",
        "\n",
        "# Evaluate on test set\n",
        "print(\"\\nEvaluating model on test set...\")\n",
        "test_images_normalized = test_images / 255.0\n",
        "metrics = model.evaluate(test_images_normalized, test_labels)\n",
        "\n",
        "print(\"\\nTest Set Metrics:\")\n",
        "for metric, value in metrics.items():\n",
        "    print(f\"{metric}: {value:.4f}\")\n",
        "\n",
        "# Plot confusion matrix\n",
        "print(\"\\nCreating confusion matrix...\")\n",
        "model.plot_confusion_matrix(test_images_normalized, test_labels, save_path='../static/confusion_matrix.png')\n",
        "\n",
        "# Detailed classification report\n",
        "predictions = model.model.predict(test_images_normalized)\n",
        "predicted_labels = (predictions > 0.5).astype(int).flatten()\n",
        "\n",
        "print(\"\\nDetailed Classification Report:\")\n",
        "print(classification_report(test_labels, predicted_labels, target_names=['Normal', 'Glaucoma']))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"4. MODEL PERFORMANCE ANALYSIS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Analyze prediction confidence distribution\n",
        "print(\"Creating confidence analysis plots...\")\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.hist(predictions[test_labels == 0], bins=20, alpha=0.7, label='Normal', color='green')\n",
        "plt.hist(predictions[test_labels == 1], bins=20, alpha=0.7, label='Glaucoma', color='red')\n",
        "plt.xlabel('Prediction Probability')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Prediction Confidence Distribution')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "confidence_scores = np.maximum(predictions.flatten(), 1 - predictions.flatten())\n",
        "plt.hist(confidence_scores, bins=20, alpha=0.7, color='blue')\n",
        "plt.xlabel('Confidence Score')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Model Confidence Distribution')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('../static/confidence_analysis.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# ROC Curve and AUC\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "fpr, tpr, _ = roc_curve(test_labels, predictions)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.3f})')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.grid(True)\n",
        "plt.savefig('../static/roc_curve.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"5. FEATURE ANALYSIS AND INTERPRETABILITY\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Grad-CAM visualization for model interpretability\n",
        "def generate_gradcam(model, img, class_index=1):\n",
        "    \"\"\"Generate Grad-CAM visualization\"\"\"\n",
        "    grad_model = tf.keras.models.Model(\n",
        "        [model.inputs], [model.layers[-2].output, model.output]\n",
        "    )\n",
        "    \n",
        "    with tf.GradientTape() as tape:\n",
        "        conv_outputs, predictions = grad_model(img)\n",
        "        loss = predictions[:, class_index]\n",
        "    \n",
        "    grads = tape.gradient(loss, conv_outputs)\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "    \n",
        "    conv_outputs = conv_outputs[0]\n",
        "    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]\n",
        "    heatmap = tf.squeeze(heatmap)\n",
        "    \n",
        "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
        "    return heatmap.numpy()\n",
        "\n",
        "# Visualize attention maps for sample images\n",
        "print(\"Creating attention maps...\")\n",
        "sample_indices = np.random.choice(len(test_images), 6, replace=False)\n",
        "\n",
        "plt.figure(figsize=(15, 10))\n",
        "for i, idx in enumerate(sample_indices):\n",
        "    img = test_images[idx:idx+1] / 255.0\n",
        "    true_label = test_labels[idx]\n",
        "    pred_prob = predictions[idx][0]\n",
        "    \n",
        "    # Generate heatmap\n",
        "    heatmap = generate_gradcam(model.model, img)\n",
        "    \n",
        "    # Resize heatmap to match image size\n",
        "    heatmap_resized = tf.image.resize(heatmap[..., np.newaxis], (224, 224)).numpy().squeeze()\n",
        "    \n",
        "    plt.subplot(2, 3, i+1)\n",
        "    plt.imshow(test_images[idx])\n",
        "    plt.imshow(heatmap_resized, alpha=0.6, cmap='jet')\n",
        "    plt.title(f'True: {true_label}, Pred: {pred_prob:.3f}')\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('../static/attention_maps.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"6. MODEL DEPLOYMENT PREPARATION\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Save model with metadata\n",
        "print(\"Saving model...\")\n",
        "model.save_model('../models/glaucoma_model.h5')\n",
        "\n",
        "# Test prediction service\n",
        "print(\"Testing prediction service...\")\n",
        "prediction_service = PredictionService('../models/glaucoma_model.h5')\n",
        "\n",
        "# Test with sample image\n",
        "sample_image = test_images[0]\n",
        "result = prediction_service.predict_single(sample_image)\n",
        "\n",
        "print(\"Sample Prediction Test:\")\n",
        "print(f\"Prediction: {result['prediction']}\")\n",
        "print(f\"Confidence: {result['confidence']:.3f}\")\n",
        "print(f\"Status: {result['status']}\")\n",
        "\n",
        "# Performance summary\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"MODEL PERFORMANCE SUMMARY\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Accuracy: {metrics['accuracy']:.4f}\")\n",
        "print(f\"Precision: {metrics['precision']:.4f}\")\n",
        "print(f\"Recall: {metrics['recall']:.4f}\")\n",
        "print(f\"F1-Score: {metrics['f1_score']:.4f}\")\n",
        "print(f\"ROC AUC: {roc_auc:.4f}\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Save performance metrics\n",
        "performance_summary = {\n",
        "    'accuracy': float(metrics['accuracy']),\n",
        "    'precision': float(metrics['precision']),\n",
        "    'recall': float(metrics['recall']),\n",
        "    'f1_score': float(metrics['f1_score']),\n",
        "    'roc_auc': float(roc_auc),\n",
        "    'training_samples': len(train_images),\n",
        "    'validation_samples': len(X_val),\n",
        "    'test_samples': len(test_images),\n",
        "    'model_parameters': model.model.count_params(),\n",
        "    'created_at': datetime.now().isoformat()\n",
        "}\n",
        "\n",
        "with open('../models/performance_summary.json', 'w') as f:\n",
        "    json.dump(performance_summary, f, indent=4)\n",
        "\n",
        "print(\"Performance summary saved to ../models/performance_summary.json\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"7. MODEL COMPARISON AND OPTIMIZATION\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Test different model architectures\n",
        "model_types = ['custom', 'vgg16', 'resnet50']\n",
        "results = {}\n",
        "\n",
        "for model_type in model_types:\n",
        "    print(f\"\\nTesting {model_type.upper()} model...\")\n",
        "    \n",
        "    try:\n",
        "        # Create model\n",
        "        test_model = GlaucomaDetectionModel(\n",
        "            input_shape=(224, 224, 3),\n",
        "            model_type=model_type\n",
        "        )\n",
        "        test_model.create_model()\n",
        "        test_model.compile_model()\n",
        "        \n",
        "        # Quick evaluation (small subset for speed)\n",
        "        subset_size = min(100, len(test_images))\n",
        "        subset_images = test_images[:subset_size] / 255.0\n",
        "        subset_labels = test_labels[:subset_size]\n",
        "        \n",
        "        metrics = test_model.evaluate(subset_images, subset_labels)\n",
        "        results[model_type] = metrics\n",
        "        \n",
        "        print(f\"{model_type.upper()} - Accuracy: {metrics['accuracy']:.4f}\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"Error with {model_type}: {str(e)}\")\n",
        "        results[model_type] = None\n",
        "\n",
        "# Compare model performances\n",
        "if len(results) > 1:\n",
        "    print(\"\\nCreating model comparison visualization...\")\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    \n",
        "    model_names = list(results.keys())\n",
        "    accuracies = [results[name]['accuracy'] if results[name] else 0 for name in model_names]\n",
        "    \n",
        "    bars = plt.bar(model_names, accuracies, color=['#667eea', '#764ba2', '#f093fb'])\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.title('Model Performance Comparison')\n",
        "    plt.ylim(0, 1)\n",
        "    \n",
        "    # Add value labels on bars\n",
        "    for bar, acc in zip(bars, accuracies):\n",
        "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
        "                f'{acc:.3f}', ha='center', va='bottom')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig('../static/model_comparison.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "# =============================================================================\n",
        "# FINAL SUMMARY\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"TRAINING AND EVALUATION COMPLETED!\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Model saved to: ../models/glaucoma_model.h5\")\n",
        "print(f\"Performance metrics saved to: ../models/performance_summary.json\")\n",
        "print(f\"Visualizations saved to: ../static/\")\n",
        "print(\"\\nNext steps:\")\n",
        "print(\"1. Start the web application: python src/app.py\")\n",
        "print(\"2. Access the dashboard at: http://localhost:8000\")\n",
        "print(\"3. Upload images for prediction\")\n",
        "print(\"4. Monitor model performance\")\n",
        "print(\"=\"*60) "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyO4cGOSPfoKHc4MunoJWeV0",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
